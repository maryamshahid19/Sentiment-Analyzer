{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa2db44c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fed1d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the paths to dataset\n",
    "train_dir_positive = 'aclImdb/train/pos'\n",
    "test_dir_positive = 'aclImdb/test/pos'\n",
    "train_dir_negative = 'aclImdb/train/neg'\n",
    "test_dir_negative = 'aclImdb/test/neg'\n",
    "train_dir_unsupervised = 'aclImdb/train/unsup'\n",
    "\n",
    "\n",
    "\n",
    "#---------------loading positive reviews--------------\n",
    "def load_positive_data(dir):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    \n",
    "    for fname in os.listdir(dir):\n",
    "        if fname.endswith('.txt'):\n",
    "            with open(os.path.join(dir, fname), encoding='utf-8') as f:\n",
    "                review = f.read()\n",
    "                reviews.append(review)\n",
    "                labels.append(1)\n",
    "    return reviews, labels\n",
    "\n",
    "#---------------loading negative reviews--------------\n",
    "def load_negative_data(dir):\n",
    "    reviews = []\n",
    "    labels = []\n",
    "    \n",
    "    for fname in os.listdir(dir):\n",
    "        if fname.endswith('.txt'):\n",
    "            with open(os.path.join(dir, fname), encoding='utf-8') as f:\n",
    "                review = f.read()\n",
    "                reviews.append(review)\n",
    "                labels.append(0)\n",
    "    return reviews, labels\n",
    "\n",
    "#---------------loading unsupervised reviews--------------\n",
    "def load_unsupervised_data(dir):\n",
    "    reviews = []\n",
    "    for fname in os.listdir(dir):\n",
    "        if fname.endswith('.txt'):\n",
    "            with open(os.path.join(dir, fname), encoding='utf-8') as f:\n",
    "                review = f.read()\n",
    "                reviews.append(review)\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e652aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------combining positive and negative reviews/labels------------\n",
    "def load_data(positive_dir, negative_dir):\n",
    "    positive_reviews, positive_labels = load_positive_data(positive_dir)\n",
    "    negative_reviews, negative_labels = load_negative_data(negative_dir)\n",
    "    reviews = positive_reviews + negative_reviews\n",
    "    labels = positive_labels + negative_labels\n",
    "    return reviews, labels\n",
    "\n",
    "\n",
    "train_reviews, train_labels = load_data(train_dir_positive, train_dir_negative)\n",
    "test_reviews, test_labels = load_data(test_dir_positive, test_dir_negative)\n",
    "unsup_reviews = load_unsupervised_data(train_dir_unsupervised)\n",
    "\n",
    "#-----------saving train and test files of reviews/labels data--------------\n",
    "def save_data(filename, data):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "save_data('train_data_rl.pkl', (train_reviews, train_labels))\n",
    "save_data('test_data_rl.pkl', (test_reviews, test_labels))\n",
    "save_data('unsupervised_data_r.pkl', unsup_reviews)\n",
    "\n",
    "#-----------tokeninzing and pre-pocessing the reviews to padded integer sequence of equal length--------------\n",
    "word_count = 8000\n",
    "words_per_review = 500\n",
    "\n",
    "tokenizer = Tokenizer(num_words=8000)\n",
    "tokenizer.fit_on_texts(train_reviews)\n",
    "\n",
    "def preprocess_reviews(tokenizer, reviews, words_per_review):\n",
    "    sequences = tokenizer.texts_to_sequences(reviews)\n",
    "    padded_sequences = pad_sequences(sequences, maxlen=words_per_review)\n",
    "    return padded_sequences\n",
    "\n",
    "x_train = preprocess_reviews(tokenizer, train_reviews, words_per_review)\n",
    "x_test = preprocess_reviews(tokenizer, test_reviews, words_per_review)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(train_labels)\n",
    "y_test = label_encoder.transform(test_labels)\n",
    "\n",
    "#----------one-hot encoding the labels to 1 for positive and 0 for negative------------\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "#------------saving files for trained/test data-------------------\n",
    "np.save('x_train_reviews.npy', x_train)\n",
    "np.save('x_test_reviews.npy', x_test)\n",
    "np.save('y_train_labels.npy', y_train)\n",
    "np.save('y_test_labels.npy', y_test)\n",
    "\n",
    "#-------save the tokenizer and label encoder as it will be needed for user input reviews as well-----------\n",
    "def save_pickle(filename, obj):\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "save_pickle('tokenizer.pkl', tokenizer)\n",
    "save_pickle('label_encoder.pkl', label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55205ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
